# BEDEO - Multi-Agent Research & Data Extraction System

A comprehensive research assistant and data extraction platform built with **AutoGen AgentChat**, **Chainlit UI**, and **GitHub-hosted LLMs** on Azure Inference. BEDEO combines academic research capabilities with advanced web crawling and ontology-based data structuring.

It simulates a full AI research and data extraction pipeline:
- ğŸ“š **Literature Agent** â€“ searches papers from arXiv & web sources
- ğŸ•·ï¸ **Web Crawling Agent** â€“ extracts and structures data from websites using BEDEO ontology
- ğŸ“„ **Document Analysis Agent** â€“ analyzes PDFs and documents
- â“ **Q&A Agent** â€“ answers follow-up questions from extracted content
- ğŸ—ï¸ **BEDEO Ontology Tools** â€“ transforms unstructured data into structured formats

---

## ğŸš€ Features

### ğŸ” Academic Research
- Dynamic academic search with arXiv integration
- Multi-source literature discovery and recommendation
- Citation analysis and research trend identification

### ğŸ•·ï¸ Web Crawling & Data Extraction
- **Enhanced Web Crawling Agent** with ontology-based transformations
- **BEDEO Ontology Integration** for structured data output
- Customizable schemas and few-shot learning capabilities
- PDF content extraction from web URLs
- Multi-depth crawling with configurable parameters

### ğŸ“„ Document Intelligence
- Multi-mode document analysis: "rapid", "academic", "visual", "enhanced"
- PDF processing and text extraction
- Content summarization and key insight identification
- Data visualization from document content

### ğŸ§  Smart Q&A System
- Context-aware question answering
- Integration with crawled and analyzed content
- External search augmentation for comprehensive responses

### ğŸ—‚ Modular Architecture
- **AutoGen + Chainlit** integration for conversational AI
- **Multi-Agent Router** for intelligent task distribution
- **Pluggable LLMs**: `gpt-4o`, `LLaMA`, `Mistral`, or custom Azure deployments

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|------------|
| **Agents** | `autogen-agentchat`, `autogen-core` |
| **Web Crawling** | `requests`, `beautifulsoup4`, `PyPDF2` |
| **Ontology** | `rdflib`, Custom BEDEO TTL parser |
| **LLMs** | GitHub-hosted models on Azure Inference |
| **Frontend** | `Chainlit` for conversational UI |
| **PDF Processing** | `PyMuPDF`, `PyPDF2` |
| **Data Processing** | `pandas`, `numpy`, `matplotlib` |

---

## ğŸ“‚ Project Structure

```
BEDEO/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ literature_agent.py              # Academic paper search
â”‚   â”œâ”€â”€ enhanced_web_crawling_agent.py   # Advanced web crawling
â”‚   â”œâ”€â”€ web_crawling_agent.py           # Basic web crawling
â”‚   â”œâ”€â”€ paper_review_agent.py           # Document analysis
â”‚   â””â”€â”€ qa_agent.py                     # Question answering
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ web_crawling_tools.py           # Web scraping utilities
â”‚   â”œâ”€â”€ bedeo_ontology_tool.py          # BEDEO ontology parser
â”‚   â”œâ”€â”€ arxiv_search_tool.py            # ArXiv integration
â”‚   â”œâ”€â”€ review_tools.py                 # Document processing
â”‚   â””â”€â”€ qa_tools.py                     # Q&A utilities
â”œâ”€â”€ orchestrator/
â”‚   â””â”€â”€ multi_agent_router.py           # Intelligent agent routing
â”œâ”€â”€ ontology/
â”‚   â””â”€â”€ bedeo.ttl                       # BEDEO ontology definition
â”œâ”€â”€ app.py                              # Chainlit entry point
â”œâ”€â”€ requirements.txt                     # Python dependencies
â”œâ”€â”€ environment.yml                      # Conda environment
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup

### ğŸ“¦ Option 1: Conda Environment (Recommended)

```bash
conda env create -f environment.yml
conda activate agent
```

### ğŸ’¡ Option 2: Pip Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # Windows: .\venv\Scripts\activate
pip install -r requirements.txt
```

---

## ğŸ” Configure Environment

Create a `.env` file:
```env
GITHUB_TOKEN=ghp_XXXXXXXXXXXXXXXXXXXXX
```

---

## ğŸš€ Run the System

```bash
chainlit run app.py
```

Then open [http://localhost:8000](http://localhost:8000)

---

## ğŸ¯ Use Cases

### ğŸ” Academic Research
- "Search for top papers on temporal graph neural networks"
- "Find recent research on quantum machine learning"
- "Recommend papers in computer vision"

### ğŸ•·ï¸ Web Crawling & Data Extraction
- "Crawl this website and extract structured data"
- "Extract real estate opportunities from this URL"
- "Transform this webpage content using BEDEO ontology"
- "Scrape and structure data from multiple URLs"

### ğŸ“„ Document Analysis
- "Analyze this PDF in enhanced mode"
- "Give me a visual summary of this paper"
- "Extract key findings from this document"

### â“ Knowledge Q&A
- "What is a temporal point process?"
- "Explain the BEDEO ontology structure"
- "How does web crawling work in this system?"

---

## ğŸ—ï¸ BEDEO Ontology

The system includes a comprehensive ontology for structuring real estate and development opportunity data:

- **Organization** â†’ **Opportunity** â†’ **RealEstateAsset** â†’ **Address**
- Supports structured data transformation from unstructured web content
- Customizable schemas for different data domains
- RDF/Turtle output format for semantic web integration

---

## ğŸ”§ Key Components

### Enhanced Web Crawling Agent
- **URL Processing**: Handles single URLs and URL lists
- **Content Extraction**: HTML, PDF, and text content parsing
- **Ontology Integration**: Transforms data using BEDEO vocabulary
- **Structured Output**: Generates organized (URL, content) pairs

### Multi-Agent Router
- **Intelligent Routing**: Automatically detects user intent
- **Dynamic Agent Selection**: Routes to appropriate specialized agents
- **Streaming Support**: Real-time token streaming for better UX

### Literature Agent
- **ArXiv Integration**: Direct access to academic papers
- **Web Search**: DuckDuckGo integration for broader research
- **Citation Analysis**: Identifies research trends and connections

---

## ğŸ“Š Limitations

- Azure Inference requires correct PAT and model permissions
- Some models do not support auto tool calling (manual fix required)
- Large PDFs are chunked to avoid context overflows
- Web crawling respects robots.txt and implements rate limiting

---

## ğŸ”® Future Work

- [ ] Add memory and persistent context across sessions
- [ ] Integrate PubMed, Semantic Scholar APIs
- [ ] Stream output for long responses
- [ ] Full PDF upload pipeline via Chainlit
- [ ] Enhanced BEDEO ontology extensions
- [ ] Multi-language web crawling support
- [ ] Advanced data visualization tools

---

## ğŸ¤ Contributing

We welcome contributions! Please feel free to:
- Report bugs and feature requests
- Submit pull requests
- Improve documentation
- Extend the BEDEO ontology

---

## ğŸ“œ License

MIT License. Use freely, modify creatively, contribute collaboratively.

---

## ğŸ™ Credits

- **Microsoft AutoGen** - Multi-agent framework
- **GitHub Models on Azure Inference** - LLM hosting
- **Chainlit.io** - Conversational UI framework
- **BEDEO Project** - Ontology and domain expertise